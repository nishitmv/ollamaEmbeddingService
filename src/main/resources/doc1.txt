In this book, we’ve taken a bottom-up approach to database system concepts: we first learned about storage structures. Now, we’re ready to move to the higher-level com‐ ponents responsible for buffer management, lock management, and recovery, which are the prerequisites for understanding database transactions. A transaction is an indivisible logical unit of work in a database management system, allowing you to represent multiple operations as a single step. Operations executed by transactions include reading and writing database records. A database transaction has to preserve atomicity, consistency, isolation, and durability. These properties are commonly referred as ACID [HAERDER83]: Atomicity Transaction steps are indivisible, which means that either all the steps associated with the transaction execute successfully or none of them do. In other words, transactions should not be applied partially. Each transaction can either commit (make all changes from write operations executed during the transaction visible), or abort (roll back all transaction side effects that haven’t yet been made visible). Commit is a final operation. After an abort, the transaction can be retried. Consistency Consistency is an application-specific guarantee; a transaction should only bring the database from one valid state to another valid state, maintaining all database invariants (such as constraints, referential integrity, and others). Consistency is the most weakly defined property, possibly because it is the only property that is controlled by the user and not only by the database itself. Isolation Multiple concurrently executing transactions should be able to run without inter‐ ference, as if there were no other transactions executing at the same time. 79Isolation defines when the changes to the database state may become visible, and what changes may become visible to the concurrent transactions. Many databases use isolation levels that are weaker than the given definition of isolation for per‐ formance reasons. Depending on the methods and approaches used for concur‐ rency control, changes made by a transaction may or may not be visible to other concurrent transactions (see “Isolation Levels” on page 96). Durability Once a transaction has been committed, all database state modifications have to be persisted on disk and be able to survive power outages, system failures, and crashes. Implementing transactions in a database system, in addition to a storage structure that organizes and persists data on disk, requires several components to work together. On the node locally, the transaction manager coordinates, schedules, and tracks transactions and their individual steps. The lock manager guards access to these resources and prevents concurrent accesses that would violate data integrity. Whenever a lock is requested, the lock manager checks if it is already held by any other transaction in shared or exclusive mode, and grants access to it if the requested access level results in no contradiction. Since exclu‐ sive locks can be held by at most one transaction at any given moment, other transac‐ tions requesting them have to wait until locks are released, or abort and retry later. As soon as the lock is released or whenever the transaction terminates, the lock manager notifies one of the pending transactions, letting it acquire the lock and continue. The page cache serves as an intermediary between persistent storage (disk) and the rest of the storage engine. It stages state changes in main memory and serves as a cache for the pages that haven’t been synchronized with persistent storage. All changes to a database state are first applied to the cached pages. The log manager holds a history of operations (log entries) applied to cached pages but not yet synchronized with persistent storage to guarantee they won’t be lost in case of a crash. In other words, the log is used to reapply these operations and recon‐ struct the cached state during startup. Log entries can also be used to undo changes done by the aborted transactions. Distributed (multipartition) transactions require additional coordination and remote execution. We discuss distributed transaction protocols in Chapter 13. 80 | Chapter 5: Transaction Processing and RecoveryBuffer Management Most databases are built using a two-level memory hierarchy: slower persistent stor‐ age (disk) and faster main memory (RAM). To reduce the number of accesses to persistent storage, pages are cached in memory. When the page is requested again by the storage layer, its cached copy is returned. Cached pages available in memory can be reused under the assumption that no other process has modified the data on disk. This approach is sometimes referenced as vir‐ tual disk [BAYER72]. A virtual disk read accesses physical storage only if no copy of the page is already available in memory. A more common name for the same concept is page cache or buffer pool. The page cache is responsible for caching pages read from disk in memory. In case of a database system crash or unorderly shutdown, cached contents are lost. Since the term page cache better reflects the purpose of this structure, this book defaults to this name. The term buffer pool sounds like its primary purpose is to pool and reuse empty buffers, without sharing their contents, which can be a useful part of a page cache or even as a separate component, but does not reflect the entire purpose as precisely. The problem of caching pages is not limited in scope to databases. Operating systems have the concept of a page cache, too. Operating systems utilize unused memory seg‐ ments to transparently cache disk contents to improve performance of I/O syscalls. Uncached pages are said to be paged in when they’re loaded from disk. If any changes are made to the cached page, it is said to be dirty, until these changes are flushed back on disk. Since the memory region where cached pages are held is usually substantially smaller than an entire dataset, the page cache eventually fills up and, in order to page in a new page, one of the cached pages has to be evicted. In Figure 5-1, you can see the relation between the logical representation of B-Tree pages, their cached versions, and the pages on disk. The page cache loads pages into free slots out of order, so there’s no direct mapping between how pages are ordered on disk and in memory. Buffer Management | 81Figure 5-1. Page cache The primary functions of a page cache can be summarized as: • It keeps cached page contents in memory. • It allows modifications to on-disk pages to be buffered together and performed against their cached versions. • When a requested page isn’t present in memory and there’s enough space avail‐ able for it, it is paged in by the page cache, and its cached version is returned. • If an already cached page is requested, its cached version is returned. • If there’s not enough space available for the new page, some other page is evicted and its contents are flushed to disk. Bypassing the Kernel Page Cache Many database systems open files using O_DIRECT flag. This flag allows I/O system calls to bypass the kernel page cache, access the disk directly, and use database- specific buffer management. This is sometimes frowned upon by the operating sys‐ tems folks. Linus Torvalds has criticized usage of O_DIRECT since it’s not asynchronous and has no readahead or other means for instructing the kernel about access patterns. How‐ ever, until operating systems start offering better mechanisms, O_DIRECT is still going to be useful. We can gain some control over how the kernel evicts pages from its cache is by using fadvise, but this only allows us to ask the kernel to consider our opinion and does not guarantee it will actually happen. To avoid syscalls when performing I/O, we can use memory mapping, but then we lose control over caching. 82 | Chapter 5: Transaction Processing and RecoveryCaching Semantics All changes made to buffers are kept in memory until they are eventually written back to disk. As no other process is allowed to make changes to the backing file, this synchronization is a one-way process: from memory to disk, and not vice versa. The page cache allows the database to have more control over memory management and disk accesses. 
